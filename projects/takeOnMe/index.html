<!-- 
  All rights given to Elgin-Skye McLaren's talk *Creative Coding & Opening Up Open Source* presented at CascadiaJS, 2018 @ Amazon Seattle 
-->

<!DOCTYPE html>
<html lang="en">
<head>
    <title>Take On Me</title>
</head>
<body>
  <p id='status'>Loading... <br>PS, once the video loads, you'll need to click to make the music start, the video toggle is at the bottom</p>

  <!-- Empty p5_loading div to prevent the the default p5 text: "Loading..." from appearing during preload -->
  <div id="p5_loading" class="loadingclass"></div>

  <!-- ML5 Posenet Library https://ml5js.org/ -->
  <script src="https://unpkg.com/ml5@0.1.2/dist/ml5.min.js"></script>

  <!-- P5 Libraries https://p5js.org/ -->
  <script src="js/p5.js"></script>
  <script src="js/p5.dom.min.js"></script>
  <script src="js/p5.sound.min.js"></script>

<script>

  // IMPORTANT: You will need to have a server running for the sketch to load locally (due to audio track), see readme
  let video;
  let poseNet;
  let poses = [];
  let color1 = 0;
  let color2 = 0;
  let videoShowing = false;
  let song;
  let analyzer;
  let speed = 1.0;
  let x = 0;
  let slowdown = false;
  let rms;

  //Have song ready before the canvas displays
  preload = () => {
    song = loadSound('assets/take-on-me.mp3');
  }

  setup = () => {
    createCanvas(window.innerWidth, window.innerHeight);
    video = createCapture(VIDEO);
    video.size(width, height);

    // Create a new poseNet method with a single detection
    poseNet = ml5.poseNet(video, modelReady);

    // This sets up an event that fills the global variable "poses"
    // with an array every time new poses are detected
    poseNet.on('pose', function (results) {
      poses = results;
    });

    // Hide the video element, and just show the canvas
    video.hide();

    // button to hide the video
    button = createButton('Show Video');
    button.mousePressed(toggleVideo);

    // create a new Amplitude analyzer
    analyzer = new p5.Amplitude();
    // Patch the input to an volume analyzer
    analyzer.setInput(song);

    // no fill in the circles
    noFill();
  }


  // Remove "Loading..."
  modelReady = () =>{
    document.getElementById("status").setAttribute("style", "display:none;");
  }

  draw = () => {
    // Get audio amplitude
    rms = analyzer.getLevel();

    // Change background color based on the audio amplitude
    bkg = map(rms, 0, 1, 255, 0);
    background(bkg, bkg, 255, 40);

    // Display the video behind the sketch (if the button has been toggled)
    if (videoShowing) {
      image(video, 0, 0, width, height);
    }

    // Make the lines change color based on wrist position
    stroke(color1, 24, color2);

    // Draw figure
    drawKeypoints();

    // Slow down the speed of the song if no one is in the frame
    slowDown();
  }


  // A function to draw ellipses over the detected keypoints
  drawKeypoints = () => {
    // Loop through all the poses detected
    for (let i = 0; i < poses.length; i++) {
      // For each pose detected, loop through all the keypoints
      for (let j = 0; j < poses[i].pose.keypoints.length; j++) {
        // A keypoint is an object describing a body part (like rightArm or leftShoulder)
        let keypoint = poses[i].pose.keypoints[j];
        // Only do the following if the pose probability is bigger than 0.2, in this case it slows down the music
        if (keypoint.score < 0.2) {
          slowdown = true;
          x = 0;
        }
        else{
          slowdown = false;
        }

        // Body keypoints
        let leftEar = poses[i].pose.keypoints[3];
        let rightEar = poses[i].pose.keypoints[4];
        let leftShoulder = poses[i].pose.keypoints[5];
        let rightShoulder = poses[i].pose.keypoints[6];
        let leftElbow = poses[i].pose.keypoints[7];
        let rightElbow = poses[i].pose.keypoints[8];
        let leftWrist = poses[i].pose.keypoints[9];
        let rightWrist = poses[i].pose.keypoints[10];
        let leftHip = poses[i].pose.keypoints[11];
        let rightHip = poses[i].pose.keypoints[12];
        let leftKnee = poses[i].pose.keypoints[13];
        let rightKnee = poses[i].pose.keypoints[14];
        let leftAnkle = poses[i].pose.keypoints[15];
        let rightAnkle = poses[i].pose.keypoints[16];

        // Average point between the ears
        let earAvgX = (leftEar.position.x+rightEar.position.x)/2;
        let earAvgY = (leftEar.position.y+rightEar.position.y)/2;

        // Average point between the hips
        let hipAvgX = (leftHip.position.x+rightHip.position.x)/2;
        let hipAvgY = (leftHip.position.y+rightHip.position.y)/2;

        // shoulders
        line(leftShoulder.position.x+random(-30, 30), leftShoulder.position.y+random(-30, 30), rightShoulder.position.x+random(-30, 30), rightShoulder.position.y+random(-30, 30));

        // left arm
        line (leftElbow.position.x+random(-30, 30), leftElbow.position.y+random(-30, 30), leftShoulder.position.x+random(-30, 30), leftShoulder.position.y+random(-30, 30));

        //right arm
        line (rightElbow.position.x+random(-30, 30), rightElbow.position.y+random(-30, 30), rightShoulder.position.x+random(-30, 30), rightShoulder.position.y+random(-30, 30));

        // left wrist
        line (leftWrist.position.x+random(-30, 30), leftWrist.position.y+random(-30, 30), leftElbow.position.x+random(-30, 30), leftElbow.position.y+random(-30, 30));

        // right wrist
        line (rightWrist.position.x+random(-30, 30), rightWrist.position.y+random(-30, 30), rightElbow.position.x+random(-30, 30), rightElbow.position.y+random(-30, 30));

        // head
        ellipse(earAvgX+random(-30, 30), earAvgY+random(-30, 30), rightEar.position.x-leftEar.position.x +random(-30, 30), rightEar.position.x-leftEar.position.x+random(-30, 30));

        // body
        line(hipAvgX+random(-30, 30), hipAvgY+random(-30, 30), leftShoulder.position.x+random(-30, 30), leftShoulder.position.y+random(-30, 30));
        line(hipAvgX+random(-30, 30), hipAvgY+random(-30, 30), rightShoulder.position.x+random(-30, 30), rightShoulder.position.y+random(-30, 30));

        // knees
        line(hipAvgX+random(-30, 30), hipAvgY+random(-30, 30), leftKnee.position.x+random(-30, 30), leftKnee.position.y+random(-30, 30));
        line(hipAvgX+random(-30, 30), hipAvgY+random(-30, 30), rightKnee.position.x+random(-30, 30), rightKnee.position.y+random(-30, 30));

        // ankles
        line(leftAnkle.position.x+random(-30, 30), leftAnkle.position.y+random(-30, 30) , leftKnee.position.x+random(-30, 30), leftKnee.position.y+random(-30, 30));
        line(rightAnkle.position.x+random(-30, 30), rightAnkle.position.y+random(-30, 30) , rightKnee.position.x+random(-30, 30), rightKnee.position.y+random(-30, 30));

        // change stroke based on user's wrist position
        color1 = map(rightWrist.position.y, 0, height, 255, 0);
        color2 = map(leftWrist.position.y, 0, height, 255, 0);
      }
    }
  }

  // Slow down the music if no one is in the frame
  slowDown = () => {
    song.rate(1-x);
    if (slowdown && x<1) {
      x+= .01;
    } else if (slowdown && x>= 1) {
      x = 1;
    } else{
      x = 0;
    }
  }

  // Toggle video on and off using button
  toggleVideo = () => {
    videoShowing = !videoShowing
  }

  // Click to start playing music
  mousePressed = () => {
    if (song.isPlaying()) {
      song.stop();
      background(255, 0, 0);
    } else {
      song.play();
      background(0, 255, 0);
    }
  }

</script>
</body>

</html>

